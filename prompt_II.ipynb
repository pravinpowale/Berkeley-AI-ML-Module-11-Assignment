{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Business Understanding\n",
    "•\tIdentify key drivers for used car prices.\n",
    "•\tConvert this business framing to a data problem definition\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Goals\n",
    "•\tTo understand how the price of a car varies according to a set of factors or features that are given in the used car dataset.\n",
    "•\tAnalyze and remove the features that are not related to the car price, before building the ML model(s).\n",
    "•\tIdentify the features (including the derived features) to build the model(s).\n",
    "•\tSelect the best performing model(s) and use them to predict the price of a car. In addition determine the factors or features that the consumers value in a car that help them decide to buy a car. Price may not be the only determining factor here.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Total ten models were built and training errors (for all 10) and test error for the model #10, which is a Ridge model in a pipeline that \n",
    "feeds into a GridSearchCV object to obtain optimal value of alpha that minimizes test_error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please refer to accompanying workbook notebook for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## df.info() shows 18 columns including id\n",
    "## Total number of records = 426880\n",
    "## columns year, price and odomter are numeric. price is the target variable\n",
    "## column cylinders is of object type but the first upto 2 characters are numeric corresponding to number of cylinders\n",
    "## column VIN was eventually discraded as it is not related to the car price and can be the source of noise in the model\n",
    "## The counts of unique values of other columns is as follows:\n",
    "'''\n",
    "nof_region 404 -- not considered for analysis\n",
    "nof_manufacturer 42 -- one hot encoding\n",
    "nof_model 29649 -- not considered for analysis \n",
    "nof_condition 6 -- ordinal encoder with ['salvage', 'fair', 'good', 'excellent', 'like new', 'new'] as the order (low to high)\n",
    "nof_cylinders 5 -- extracted leading up to 2 characters and converted to number of cyliders (ncyl column)\n",
    "nof_fuel 5 -- one hot encoder\n",
    "nof_title_status 6 -- one hot encoder \n",
    "nof_transmission 3 - one hot encoder\n",
    "nof_drive 3 -- one hot encoder\n",
    "nof_type 13 -- one hot encoder\n",
    "nof_paint_color 12 -- one hot encoder\n",
    "nof_state 51 -- frequency encoder\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Out of the 10 models built, first 5 were built using price column as the target variable\n",
    "## The training error (mse) of each of these 5 models was very high - order of magnitude 10^14\n",
    "## As a result a new column log_price was created by taking the natural logarithm of price\n",
    "## this brought down the mse to single digit before the decimal point\n",
    "## Please refer to the accompanying workbook for computed mses for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The accompnaying workbook notebook has the steps to clean the data\n",
    "## Region column was not considered for analysis as it has a large number of unique values (304) and also appears to be correlated with state\n",
    "## though this correlation was not assumed to be true\n",
    "## Simailarly VIN and model columns were dropped\n",
    "## Rows with NaN values were removed \n",
    "## a numeric column ncyl was created to represent number of cylinders using the cylider column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for models #6 to #10, the log_price column as used\n",
    "## for creating the log_price column all rows with price = 0 were removed to avoid NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please refer to the accompanying workbook for the 10 different models\n",
    "## out of which the first 5 models use the price column as the target variable\n",
    "## and the last 5 use the log_price as the target variable\n",
    "## The training and test mse (only for model #10) were in single digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The first 5 models that used price as the target variable are not practical due very large error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The last 5 models (#6 through #10 are described below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model #6 uses ncyl and log_price\n",
    "it uses LinearRegression model\n",
    "traning error taken on the whole dataframe is mod6_mse = 6.8816110644533195\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model #7 uses ['condition', 'transmission', 'drive', 'type', 'ncyl'] with condition as ordinalencoder\n",
    "transmission, drive, type as onehotencoder\n",
    "ncyl in PolynomialFeatures object (degree = 3)\n",
    "as part of a pipeline\n",
    "traning error taken on the whole dataframe is mod7_mse = 1.3119076332608168\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model #8 uses 1 ordinalencoder, 8 onehotencoders and 4 PolynomialFeature objects (ncyl, odometer, year, f_state (derived from frequency of each state))\n",
    "with ncyl having degree = 3 and remaining degree = 1\n",
    "traning error taken on the whole dataframe is mod8_mse = 1.668658711858038\n",
    "model #8 has total 94 features as a result of various encoders and PolynomialFeatures\n",
    "After doing the analysis of p-values (< 0.05) and t-statistics, both yielded the same set of 7 most significant features given below\n",
    "\n",
    "Most significant features\n",
    "col#\tcol_name\n",
    "\n",
    "90    polynomialfeatures-1__ncyl^3  \n",
    "91      polynomialfeatures-2__year\n",
    "92  polynomialfeatures-3__odometer\n",
    "93   polynomialfeatures-4__f_state\n",
    "0        ordinalencoder__condition\n",
    "89    polynomialfeatures-1__ncyl^2\n",
    "88      polynomialfeatures-1__ncyl\n",
    "\n",
    "#### Plase see the workbook for the code\n",
    "traning error taken on the whole dataframe is mod8_mse = 1.668658711858038\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model #9 uses the Sequential feature Selection on model #8 (mod8)\n",
    "The input dataframee is shuffled and split into 80% train and 20% test indices\n",
    "n_features_to_select = 7\n",
    "training error is 1.3144517741100517\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model 10 uses GridSearchCV and Ridge regressor alongwith the same ColumnTransformer as in model 8 (94 features)\n",
    "Best value of alpha is 1e-05\n",
    "Corresponding Test mse is 1.191933129669491\n",
    "Corresponding train mse is ~ 1.225\n",
    "The plots of Test mse and train mse vs alpha are provided in the workbook (2 individual and 1 superimposed) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As explained above the 7 features given below seem to drive the price of a car based upon the statistical analysis performed\n",
    "in the accompanying workbook. \n",
    "\n",
    "col#\tcol_name\n",
    "\n",
    "90    polynomialfeatures-1__ncyl^3  \n",
    "91      polynomialfeatures-2__year\n",
    "92  polynomialfeatures-3__odometer\n",
    "93   polynomialfeatures-4__f_state\n",
    "0        ordinalencoder__condition\n",
    "89    polynomialfeatures-1__ncyl^2\n",
    "88      polynomialfeatures-1__ncyl\n",
    "\n",
    "This maps to five original features of the dataset viz.\n",
    "cylinders, year, odometer, state and condition\n",
    "\n",
    "         p-Value      t-Statistic  \n",
    "91  0.000000e+00        38.881176  \n",
    "93  0.000000e+00       -22.405576  \n",
    "92  0.000000e+00       -20.948704  \n",
    "90  0.000000e+00        -8.655205  \n",
    "0   2.308564e-09         5.975176  \n",
    "89  2.508449e-06         4.707799  \n",
    "88  9.171664e-01         0.104004 \n",
    "\n",
    "This is quite intutive as well as\n",
    "\n",
    "feature #92 (odometer) has negative t-statistic which implies price decreaes as odometer reading increases\n",
    "feature #91 (year) has positive t-statistic which implies price increses as the year increses (age of the car decreses)\n",
    "also ncyl is not a significant feature in itself but ncyl^2 and ncyl^3 are\n",
    "\n",
    "Finally, out of the 10 models described above and computed in the workbook, the Ridge model seems to be best in performance due to\n",
    "its very low test error\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
